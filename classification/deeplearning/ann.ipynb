{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pickles for Reddit ADHD Dataset with all classes. Replace filenames after running preprocessing to create pickles. \n",
    "with open('eval-x-file', 'rb') as file:\n",
    "    evaluation_x = pickle.load(file)\n",
    "\n",
    "with open('eval-y-file', 'rb') as file:\n",
    "    evaluation_y = pickle.load(file)\n",
    "\n",
    "with open('x-train-file', 'rb') as file:\n",
    "    X_training = pickle.load(file)\n",
    "\n",
    "with open('y-train-file', 'rb') as file:\n",
    "    y_training = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#designing the model by adding layers. Parameters can be changed here. \n",
    "input_shape = (1000,)\n",
    "\n",
    "ann_model = Sequential([\n",
    "    Dense(1000, input_shape=input_shape, activation='relu'),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model. Learning rate value can be changed here. \n",
    "ann_model.compile(optimizer=Adam(learning_rate=0.005), \n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=['accuracy']) \n",
    "  \n",
    "# fitting the model. Number of epoochs and batch size can be changed here. \n",
    "ann_model.fit(X_training, y_training, epochs=10, batch_size=64, validation_data=(evaluation_x, evaluation_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.evaluate(evaluation_x, evaluation_y, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of predictions\n",
    "predictions = ann_model.predict(evaluation_x)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(evaluation_y, predicted_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(evaluation_y, predicted_labels, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "#creating the confusion matrix\n",
    "cm = confusion_matrix(evaluation_y, predicted_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(evaluation_y))\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
